Unlike prior works using self-attention in computer vision, they do not introduce any image-specific inductive biases into the architecture. Instead, they interpret an image as a sequence of patches and process it by a standard Transformer encoder as used NLP. This simple, yet scalable, strategy works surprisingly theyll when coupled with pre-training on large datasets. Thus, Vision Transformer matches or exceeds the state of the art on many image classification datasets, whilst being relatively cheap to re-train. NLP. This simple, yet scalable, strategy works surprisingly theyll when coupled with pre-training on large datasets. Thus, Vision Transformer matches or exceeds the state of the art on many image classification datasets, whilst being relatively cheap to re-train.re-train.